# -*- coding: utf-8 -*-
"""mentor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11B4zUK683L73YqZzyrPP06AlxJBu5xzz
"""

import torch
import torch.nn as nn
import torchvision.models as models

class TeacherModel(nn.Module):
    def __init__(self, model_name='resnet50', num_classes=100):
        super().__init__()

        if model_name == 'resnet50':
            backbone = torch.load('resnet50_cifar100-30adam.pth', weights_only=False)
            feature_dim = 2048
            backbone.fc = nn.Identity()
        elif model_name == 'vit':
            backbone = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)
            feature_dim = 768
            backbone.heads.head = nn.Identity()
        else:
            raise ValueError(f"Unsupported model: {model_name}")

        self.backbone = backbone
        self.mc_classifier = self._build_classifier(feature_dim, num_classes)
        self.binary_classifier = self._build_classifier(feature_dim, 1)

    def _build_classifier(self, in_dim, out_dim):
        return nn.Sequential(
            nn.Linear(in_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, out_dim)
        )

    def forward(self, x):
        features = self.backbone(x)
        mc_logit = self.mc_classifier(features)
        binary_logit = self.binary_classifier(features)
        return mc_logit, binary_logit

class DistillationLoss(nn.Module):
    def __init__(self, temperature=3.0):
        super(DistillationLoss, self).__init__()
        self.temperature = temperature

    def forward(self, student_logits, teacher_logits):
        student_logits_temp = student_logits / self.temperature
        teacher_logits_temp = teacher_logits / self.temperature

        soft_loss = F.kl_div(
            F.log_softmax(student_logits_temp, dim=1),  # student logits as input (log probs)
            F.softmax(teacher_logits_temp, dim=1),      # teacher logits as target (probs)
            reduction='batchmean'
        )

        return soft_loss * (self.temperature ** 2)